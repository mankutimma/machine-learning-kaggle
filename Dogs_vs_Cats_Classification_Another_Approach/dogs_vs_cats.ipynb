{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 802 images belonging to 2 classes.\n",
      "Epoch 1/30\n",
      "125/125 [==============================] - 74s - loss: 0.7001 - acc: 0.5525 - val_loss: 0.6829 - val_acc: 0.5475\n",
      "Epoch 2/30\n",
      "125/125 [==============================] - 54s - loss: 0.6676 - acc: 0.6030 - val_loss: 0.6302 - val_acc: 0.6628\n",
      "Epoch 3/30\n",
      "125/125 [==============================] - 56s - loss: 0.6381 - acc: 0.6525 - val_loss: 0.6213 - val_acc: 0.6743\n",
      "Epoch 4/30\n",
      "125/125 [==============================] - 55s - loss: 0.6043 - acc: 0.6755 - val_loss: 0.5910 - val_acc: 0.6692\n",
      "Epoch 5/30\n",
      "125/125 [==============================] - 55s - loss: 0.5975 - acc: 0.6910 - val_loss: 0.5654 - val_acc: 0.6947\n",
      "Epoch 6/30\n",
      "125/125 [==============================] - 55s - loss: 0.5614 - acc: 0.7200 - val_loss: 0.5659 - val_acc: 0.6972\n",
      "Epoch 7/30\n",
      "125/125 [==============================] - 54s - loss: 0.5436 - acc: 0.7280 - val_loss: 0.5513 - val_acc: 0.7112\n",
      "Epoch 8/30\n",
      "125/125 [==============================] - 54s - loss: 0.5453 - acc: 0.7310 - val_loss: 0.5189 - val_acc: 0.7290\n",
      "Epoch 9/30\n",
      "125/125 [==============================] - 53s - loss: 0.5270 - acc: 0.7445 - val_loss: 0.5011 - val_acc: 0.7379\n",
      "Epoch 10/30\n",
      "125/125 [==============================] - 54s - loss: 0.5176 - acc: 0.7610 - val_loss: 0.5411 - val_acc: 0.7303\n",
      "Epoch 11/30\n",
      "125/125 [==============================] - 54s - loss: 0.5221 - acc: 0.7390 - val_loss: 0.5004 - val_acc: 0.7545\n",
      "Epoch 12/30\n",
      "125/125 [==============================] - 57s - loss: 0.4896 - acc: 0.7675 - val_loss: 0.5053 - val_acc: 0.7621\n",
      "Epoch 13/30\n",
      "125/125 [==============================] - 57s - loss: 0.4949 - acc: 0.7710 - val_loss: 0.5400 - val_acc: 0.7137\n",
      "Epoch 14/30\n",
      "125/125 [==============================] - 62s - loss: 0.4974 - acc: 0.7640 - val_loss: 0.4623 - val_acc: 0.7888\n",
      "Epoch 15/30\n",
      "125/125 [==============================] - 60s - loss: 0.4807 - acc: 0.7780 - val_loss: 0.5799 - val_acc: 0.7176\n",
      "Epoch 16/30\n",
      "125/125 [==============================] - 77s - loss: 0.4814 - acc: 0.7760 - val_loss: 0.5399 - val_acc: 0.7328\n",
      "Epoch 17/30\n",
      "125/125 [==============================] - 60s - loss: 0.4526 - acc: 0.7950 - val_loss: 0.4998 - val_acc: 0.7634\n",
      "Epoch 18/30\n",
      "125/125 [==============================] - 53s - loss: 0.4509 - acc: 0.8025 - val_loss: 0.4910 - val_acc: 0.7710\n",
      "Epoch 19/30\n",
      "125/125 [==============================] - 56s - loss: 0.4394 - acc: 0.8045 - val_loss: 0.4677 - val_acc: 0.8092\n",
      "Epoch 20/30\n",
      "125/125 [==============================] - 55s - loss: 0.4462 - acc: 0.8055 - val_loss: 0.5059 - val_acc: 0.7583\n",
      "Epoch 21/30\n",
      "125/125 [==============================] - 55s - loss: 0.4386 - acc: 0.8055 - val_loss: 0.5281 - val_acc: 0.7443\n",
      "Epoch 22/30\n",
      "125/125 [==============================] - 53s - loss: 0.4587 - acc: 0.7945 - val_loss: 0.5724 - val_acc: 0.7468\n",
      "Epoch 23/30\n",
      "125/125 [==============================] - 53s - loss: 0.4435 - acc: 0.8070 - val_loss: 0.5216 - val_acc: 0.7799\n",
      "Epoch 24/30\n",
      "125/125 [==============================] - 54s - loss: 0.4353 - acc: 0.8085 - val_loss: 0.5078 - val_acc: 0.7595\n",
      "Epoch 25/30\n",
      "125/125 [==============================] - 53s - loss: 0.4376 - acc: 0.8155 - val_loss: 0.4879 - val_acc: 0.7697\n",
      "Epoch 26/30\n",
      "125/125 [==============================] - 53s - loss: 0.4197 - acc: 0.8115 - val_loss: 0.5122 - val_acc: 0.7824\n",
      "Epoch 27/30\n",
      "125/125 [==============================] - 54s - loss: 0.4271 - acc: 0.8175 - val_loss: 0.4599 - val_acc: 0.7875\n",
      "Epoch 28/30\n",
      "125/125 [==============================] - 53s - loss: 0.4256 - acc: 0.8060 - val_loss: 0.5221 - val_acc: 0.7697\n",
      "Epoch 29/30\n",
      "125/125 [==============================] - 54s - loss: 0.4254 - acc: 0.8190 - val_loss: 0.6070 - val_acc: 0.7290\n",
      "Epoch 30/30\n",
      "125/125 [==============================] - 53s - loss: 0.4004 - acc: 0.8330 - val_loss: 0.5401 - val_acc: 0.7455\n"
     ]
    }
   ],
   "source": [
    "'''This script goes along the blog post\n",
    "\"Building powerful image classification models using very little data\"\n",
    "from blog.keras.io.\n",
    "It uses data that can be downloaded at:\n",
    "https://www.kaggle.com/c/dogs-vs-cats/data\n",
    "In our setup, we:\n",
    "- created a data/ folder\n",
    "- created train/ and validation/ subfolders inside data/\n",
    "- created cats/ and dogs/ subfolders inside train/ and validation/\n",
    "- put the cat pictures index 0-999 in data/train/cats\n",
    "- put the cat pictures index 1000-1400 in data/validation/cats\n",
    "- put the dogs pictures index 12500-13499 in data/train/dogs\n",
    "- put the dog pictures index 13500-13900 in data/validation/dogs\n",
    "So that we have 1000 training examples for each class, and 400 validation examples for each class.\n",
    "In summary, this is our directory structure:\n",
    "```\n",
    "data/\n",
    "    train/\n",
    "        dogs/\n",
    "            dog001.jpg\n",
    "            dog002.jpg\n",
    "            ...\n",
    "        cats/\n",
    "            cat001.jpg\n",
    "            cat002.jpg\n",
    "            ...\n",
    "    validation/\n",
    "        dogs/\n",
    "            dog001.jpg\n",
    "            dog002.jpg\n",
    "            ...\n",
    "        cats/\n",
    "            cat001.jpg\n",
    "            cat002.jpg\n",
    "            ...\n",
    "```\n",
    "'''\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.python.keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from tensorflow.python.keras import backend as K\n",
    "\n",
    "\n",
    "# dimensions of our images.\n",
    "img_width, img_height = 150, 150\n",
    "\n",
    "train_data_dir = 'data/train'\n",
    "validation_data_dir = 'data/validation'\n",
    "nb_train_samples = 2000\n",
    "nb_validation_samples = 800\n",
    "epochs = 30 #50\n",
    "batch_size = 16\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, img_width, img_height)\n",
    "else:\n",
    "    input_shape = (img_width, img_height, 3)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=nb_validation_samples // batch_size)\n",
    "\n",
    "model.save_weights('first_try.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.5434517912737286\n",
      "Test accuracy: 0.7379134860050891\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate_generator(validation_generator, nb_validation_samples // batch_size)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('kerasModel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.models import load_model\n",
    "model2 = load_model('kerasModel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['11.jpg', '9.jpg', '7.jpg', '17.jpg', '6.jpg', '19.jpg', '2.jpg', '14.jpg', '10.jpg', '13.jpg', '20.jpg', '3.jpg', '12.jpg', '15.jpg', '8.jpg', '4.jpg', '18.jpg', '16.jpg', '1.jpg', '5.jpg']\n",
      "1/1 [==============================] - 0s\n",
      "1/1 [==============================] - 0s\n",
      "the image: 11.jpg has prediction class:[[0]] and prediction probability: [[0.]]\n",
      "1/1 [==============================] - 0s\n",
      "1/1 [==============================] - 0s\n",
      "the image: 9.jpg has prediction class:[[0]] and prediction probability: [[0.]]\n",
      "1/1 [==============================] - 0s\n",
      "1/1 [==============================] - 0s\n",
      "the image: 7.jpg has prediction class:[[0]] and prediction probability: [[0.]]\n",
      "1/1 [==============================] - 0s\n",
      "1/1 [==============================] - 0s\n",
      "the image: 17.jpg has prediction class:[[1]] and prediction probability: [[1.]]\n",
      "1/1 [==============================] - 0s\n",
      "1/1 [==============================] - 0s\n",
      "the image: 6.jpg has prediction class:[[1]] and prediction probability: [[1.]]\n",
      "1/1 [==============================] - 0s\n",
      "1/1 [==============================] - 0s\n",
      "the image: 19.jpg has prediction class:[[1]] and prediction probability: [[1.]]\n",
      "1/1 [==============================] - 0s\n",
      "1/1 [==============================] - 0s\n",
      "the image: 2.jpg has prediction class:[[1]] and prediction probability: [[1.]]\n",
      "1/1 [==============================] - 0s\n",
      "1/1 [==============================] - 0s\n",
      "the image: 14.jpg has prediction class:[[1]] and prediction probability: [[1.]]\n",
      "1/1 [==============================] - 0s\n",
      "1/1 [==============================] - 0s\n",
      "the image: 10.jpg has prediction class:[[0]] and prediction probability: [[0.]]\n",
      "1/1 [==============================] - 0s\n",
      "1/1 [==============================] - 0s\n",
      "the image: 13.jpg has prediction class:[[1]] and prediction probability: [[1.]]\n",
      "1/1 [==============================] - 0s\n",
      "1/1 [==============================] - 0s\n",
      "the image: 20.jpg has prediction class:[[1]] and prediction probability: [[1.]]\n",
      "1/1 [==============================] - 0s\n",
      "1/1 [==============================] - 0s\n",
      "the image: 3.jpg has prediction class:[[1]] and prediction probability: [[1.]]\n",
      "1/1 [==============================] - 0s\n",
      "1/1 [==============================] - 0s\n",
      "the image: 12.jpg has prediction class:[[1]] and prediction probability: [[1.]]\n",
      "1/1 [==============================] - 0s\n",
      "1/1 [==============================] - 0s\n",
      "the image: 15.jpg has prediction class:[[0]] and prediction probability: [[3.4689995e-37]]\n",
      "1/1 [==============================] - 0s\n",
      "1/1 [==============================] - 0s\n",
      "the image: 8.jpg has prediction class:[[1]] and prediction probability: [[1.]]\n",
      "1/1 [==============================] - 0s\n",
      "1/1 [==============================] - 0s\n",
      "the image: 4.jpg has prediction class:[[1]] and prediction probability: [[1.]]\n",
      "1/1 [==============================] - 0s\n",
      "1/1 [==============================] - 0s\n",
      "the image: 18.jpg has prediction class:[[1]] and prediction probability: [[1.]]\n",
      "1/1 [==============================] - 0s\n",
      "1/1 [==============================] - 0s\n",
      "the image: 16.jpg has prediction class:[[0]] and prediction probability: [[0.]]\n",
      "1/1 [==============================] - 0s\n",
      "1/1 [==============================] - 0s\n",
      "the image: 1.jpg has prediction class:[[1]] and prediction probability: [[1.]]\n",
      "1/1 [==============================] - 0s\n",
      "1/1 [==============================] - 0s\n",
      "the image: 5.jpg has prediction class:[[0]] and prediction probability: [[0.]]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tensorflow.python.keras.preprocessing.image import img_to_array, load_img\n",
    "import numpy as np\n",
    "\n",
    "def predict():\n",
    "    print(os.listdir('data/test/'))\n",
    "    for image_file in os.listdir('data/test/'):\n",
    "        x = img_to_array(load_img('data/test/' + image_file, False, target_size=(img_width, img_height)))\n",
    "        #x = x // 255\n",
    "        x = np.expand_dims(x, axis = 0)\n",
    "        prediction = model2.predict_classes(x)\n",
    "        probability = model2.predict_proba(x)\n",
    "        print('the image: {} has prediction class:{} and prediction probability: {}'.format(image_file, prediction, probability))\n",
    "        \n",
    "predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cats': 0, 'dogs': 1}\n"
     ]
    }
   ],
   "source": [
    "print(train_generator.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cats': 0, 'dogs': 1}\n"
     ]
    }
   ],
   "source": [
    "print(validation_generator.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.keras._impl.keras.preprocessing.image.DirectoryIterator'>\n"
     ]
    }
   ],
   "source": [
    "print(type(train_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
